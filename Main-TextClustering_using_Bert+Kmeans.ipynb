{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised_TextClustering_using_Bert+Kmeans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PEqp53GvY0T"
      },
      "source": [
        "# library to find the elbow in kmeans clustering\n",
        "!pip install kneed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "530m0dbayKQ7"
      },
      "source": [
        "# library to encode the sentences\n",
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMluvu1WxRKN"
      },
      "source": [
        "# downloading all data and unziping them\n",
        "!gdown --id 13dBDebbbBLfTg0-jbiJMh6u9NtEJ6T8l\n",
        "!unzip \"/content/changeadvisor-dataset.zip\" -d \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpwvhWZOvFRs"
      },
      "source": [
        "# importing all relevant libraries for use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from kneed import KneeLocator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "import re\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqIVnHMSH5px"
      },
      "source": [
        "# a function that takes text and returns the embeddings. The return shape is \n",
        "# (N,768) where n is the number of reviews \n",
        "def get_embeddings(text):\n",
        "  # loading the bert model\n",
        "  bert_model = SentenceTransformer('bert-base-uncased')\n",
        "  # encoding and returning the embeddings\n",
        "  embeddings = bert_model.encode(text)\n",
        "  return embeddings"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChEBiD0iHMpA"
      },
      "source": [
        "# getting the best k. The fucntion takes the embeddings and the range between which we think the k will be\n",
        "def get_k(embeddings,starting_range = 1,ending_range=10):\n",
        "  \n",
        "  k_range = range(starting_range,ending_range)\n",
        "  WSS = []\n",
        "  # looping over all the k from starting to endings\n",
        "  for k in k_range:\n",
        "    # initializing 1 by 1 kmeans clustering algo with different k from the range\n",
        "      km_cluster = KMeans(n_clusters = k,algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
        "      n_init=10, n_jobs=None, precompute_distances='auto',\n",
        "      random_state=0, tol=0.0001, verbose=0)\n",
        "\n",
        "    # fitting the embeddings on kmeans to get the inertia\n",
        "      km_cluster.fit(embeddings)\n",
        "      # saving the inertia to find the elbow\n",
        "      WSS.append(km_cluster.inertia_)\n",
        "  \n",
        "  # after the loop is over we have intertia(WSS) for each value of k which we provide to kneelocater to get us the elbow k value\n",
        "  elbow_locator = KneeLocator(k_range, WSS, curve='convex', direction='decreasing')\n",
        "  elbow_point = elbow_locator.knee - 1\n",
        "  \n",
        "  return elbow_point"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8zQLqEDHsR6"
      },
      "source": [
        "# this takes in the embeddings and text and also the best k value and clusters the data accordingly\n",
        "# after it stores the data in csv\n",
        "def cluster_reviews(embeddings,text,best_k,filename ='Clustered_Data.csv'):\n",
        "  # initializing the kmeans with best k \n",
        "  clustering_model = KMeans(n_clusters=best_k,algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
        "      n_init=10, n_jobs=None, precompute_distances='auto',\n",
        "      random_state=0, tol=0.0001, verbose=0)\n",
        "  # fitting the kmeans on embeddings\n",
        "  clustering_model.fit(embeddings)\n",
        "  # getting the labels for each row(Review) provided to kmeans\n",
        "  cluster_assignment = clustering_model.labels_\n",
        "  # putting it with text and storing in csv file\n",
        "  print('Saving the clustered result in a csv file')\n",
        "  print('--------------------------------------- \\n')\n",
        "  data = pd.DataFrame(list(zip(text, cluster_assignment)),\n",
        "               columns =['Text', 'Cluster'])\n",
        "  data.to_csv(filename)\n",
        "  print('Process Done!!!')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYlPuIFpdAQR"
      },
      "source": [
        "# the main function which starts it all\n",
        "def main(filepath = \"/content/reviews/com.achep.acdisplay.txt\"):\n",
        "  # get filename   \n",
        "  filename = re.findall(r'[\\w.]*.txt', filepath)[0]\n",
        "\n",
        "  #  reading the files of reviews \n",
        "  print(\"Reading the the text data...\")\n",
        "  print('--------------------------------------- \\n')\n",
        "  my_file = open(filepath, \"r\")\n",
        "  content = my_file.read()\n",
        "  content_list = content.split(\"\\n\")\n",
        "  my_file.close()\n",
        "\n",
        "  # getting the embeddings for all reviews\n",
        "  # currently its reduce to 100 you can change the value or either remove [] to work on full data\n",
        "  print(\"Creating embeddings from the text data...\")\n",
        "  print('--------------------------------------- \\n')\n",
        "  embeddings = get_embeddings(content_list[:100])\n",
        "  # getting the best k\n",
        "  print(\"\\nDetermining the best K for the embedded data...\")\n",
        "  print('--------------------------------------- \\n')\n",
        "  k_value = get_k(embeddings,1,10)\n",
        "  # getting the review with clusters\n",
        "  print(\"Applying Kmeans with the best K to the embedded data...\")\n",
        "  print('-------------------------------------- \\n')\n",
        "  cluster_reviews(embeddings,content_list,k_value,filename)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ubZeqQlJ0FI",
        "outputId": "1b61d443-02d9-46cf-9424-7e546a7291f6"
      },
      "source": [
        "# calling main\n",
        "main()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the the text data...\n",
            "--------------------------------------- \n",
            "\n",
            "Creating embeddings from the text data...\n",
            "--------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Determining the best K for the embedded data...\n",
            "--------------------------------------- \n",
            "\n",
            "Applying Kmeans with the best K to the embedded data...\n",
            "-------------------------------------- \n",
            "\n",
            "Saving the clustered result in a csv file\n",
            "--------------------------------------- \n",
            "\n",
            "Process Done!!!\n"
          ]
        }
      ]
    }
  ]
}